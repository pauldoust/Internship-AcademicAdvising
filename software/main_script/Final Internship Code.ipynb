{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************* Initialization ********************************************\n",
    "\n",
    "####################\n",
    "##### Imports ######\n",
    "####################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import os\n",
    "####################\n",
    "#### Parameters ####\n",
    "####################\n",
    "Experiment = \"\\SecondSemester\"\n",
    "DataFolder = \"\\data\\\\\"\n",
    "OrPath = r\"C:\\Users\\mpouldou\\final-data\" + \"\\SecondSemester\" + DataFolder\n",
    "# Path = r\"C:\\Users\\mpouldou\\final-data\" + Experiment + DataFolder\n",
    "MainPath = r\"C:\\Users\\mpouldou\\final-data\"\n",
    "semesterFilePath = r\"C:\\Users\\mpouldou\\final-data\" + Experiment + DataFolder + \"semesters.txt\"\n",
    "# Courses_to_include = ['FIEC03012', 'ICM00604', 'ICM00646', 'ICF00489', 'ICM00216', 'ICF00463', 'FIEC04341', 'FIEC04358', 'ICM00901']\n",
    "Features_Set = set([ 'NEW_COD_STUDENT', 'SEMESTER', 'YEAR', 'COURSE_ID', 'GRADE', 'GPA', 'PROFESSOR_ID', 'ID'])\n",
    "\n",
    "# Courses_to_include = ['FIEC03012', 'ICM00604', 'ICM00646', 'ICF00489', 'ICM00216', 'ICF00463', 'FIEC04341', 'FIEC04358', 'ICM00901']\n",
    "# Target_Courses = ['FIEC03012', 'ICM00604', 'ICM00646', 'ICF00489']\n",
    "# Target_Courses_amax = [('amax', 'FIEC03012'), ('amax', 'ICM00604'), ('amax', 'ICM00646'), ('amax', 'ICF00489')]\n",
    "# Target_Courses_prev = [('PrevLatestGrade', 'FIEC03012'), ('PrevLatestGrade', 'ICM00604'), ('PrevLatestGrade', 'ICM00646'), ('PrevLatestGrade', 'ICF00489')]\n",
    "# Target_Courses_count = [('count', 'FIEC03012'), ('count', 'ICM00604'), ('count', 'ICM00646'), ('count', 'ICF00489')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_historic_data( historia_academia_path, teaching_materials_path, graduates_all_dep_path, Experiment):\n",
    "    df_historia_academia = pd.read_csv(historia_academia_path)\n",
    "    df_teaching_materials = pd.read_csv(teaching_materials_path)\n",
    "    df_graduates_all_dep = pd.read_csv(graduates_all_dep_path)\n",
    "    \n",
    "    \n",
    "    df_historia_academia_extended = pd.merge(df_historia_academia, df_teaching_materials, on=[\"COURSE_ID\", \"COURSE_TRACK\", \"YEAR\", \"SEMESTER\"])\n",
    "\n",
    "    df_historia_academia_extended.SEMESTER = df_historia_academia_extended.SEMESTER.apply(lambda x: \"1T\" if x == \"1S\" else x)\n",
    "    df_historia_academia_extended.SEMESTER = df_historia_academia_extended.SEMESTER.apply(lambda x: \"2T\" if x == \"2S\" else x)\n",
    "    df_historia_academia_extended.SEMESTER = df_historia_academia_extended.SEMESTER.apply(lambda x: \"3T\" if x == \"3S\" else x)\n",
    "\n",
    "    df_historia_academia_extended2 = df_historia_academia_extended.to_csv (MainPath +Experiment+ \"\\\\historia_academia_extended.csv\", index = None, header=True) \n",
    "\n",
    "    df_dataset = pd.merge(df_graduates_all_dep, df_historia_academia_extended, on=[\"NEW_COD_STUDENT\"])\n",
    "\n",
    "    \n",
    "    df_dataset2 = df_dataset.to_csv (MainPath + Experiment + \"\\\\dataset_joined.csv\", index = None, header=True) \n",
    "\n",
    "    return df_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatentated_grades(x):\n",
    "     return \",\".join([str(y) for y in x])\n",
    "\n",
    "def PrevLatestGrade(x):\n",
    "    if len(x.values) == 1:\n",
    "        return x.values[0]\n",
    "    else:\n",
    "        return x.values[1]\n",
    "\n",
    "    \n",
    "def Sum_GPA_Squared(x):\n",
    "     return (x * x).sum()\n",
    "    \n",
    "def Sum_GPAxMARK(x):\n",
    "    return (x['GRADE'] * x['GPA']).sum()\n",
    "\n",
    "def Sum_GPAsubMARK(x):\n",
    "    return (x['GPA'] - x['GRADE']).sum()\n",
    "\n",
    "def SkewnessOfDifferences(x):\n",
    "    return (x['GPA'] - x['GRADE']).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset( joined_data, Courses_to_include, Experiment):\n",
    "    \n",
    "    df_flow = joined_data.loc[ (joined_data['COURSE_ID'].isin( Courses_to_include )) ]     \n",
    "    df_flow.SEMESTER = df_flow.SEMESTER.apply(lambda x: \"1T\" if x == \"1S\" else x)\n",
    "    df_flow.SEMESTER = df_flow.SEMESTER.apply(lambda x: \"2T\" if x == \"2S\" else x)\n",
    "    df_flow.SEMESTER = df_flow.SEMESTER.apply(lambda x: \"3T\" if x == \"3S\" else x)\n",
    "\n",
    "    df_flow.GRADE = df_flow.GRADE.replace({',': '.'}, regex=True)\n",
    "    df_flow.GRADE = pd.to_numeric(df_flow.GRADE)\n",
    "            \n",
    "    df_flow2 = df_flow.to_csv (MainPath + Experiment + \"\\\\\" + Experiment + \"_flow.csv\" , index = None, header=True)\n",
    "    return df_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marks_features_extraction(cleanded_data, Target_Course, Target_Courses_amax, Experiment):\n",
    "    features_set = set([ 'NEW_COD_STUDENT', 'SEMESTER', 'YEAR', 'COURSE_ID', 'GRADE', 'GPA', 'PROFESSOR_ID', 'ID'])\n",
    "\n",
    "    for column in cleanded_data:\n",
    "        if column not in features_set:\n",
    "            cleanded_data = cleanded_data.drop(column, axis=1)\n",
    "        \n",
    "    cleanded_data = cleanded_data.sort_values(by=['NEW_COD_STUDENT','COURSE_ID', 'YEAR', 'SEMESTER'],ascending=[False, False, False,False])\n",
    "    df_flow_pivot = cleanded_data.pivot_table(index='NEW_COD_STUDENT', columns='COURSE_ID', values='GRADE', aggfunc=[ np.max, PrevLatestGrade, 'count'])\n",
    "\n",
    "    df_flow_pivot = pd.merge(cleanded_data, df_flow_pivot, how=\"inner\",on=\"NEW_COD_STUDENT\")\n",
    "    targetCol = ('count', Target_Course)\n",
    "    \n",
    "    df_flow_pivot[targetCol] = df_flow_pivot[targetCol].apply(lambda x: x-1)\n",
    "    \n",
    "#     df_flow_pivot = df_flow_pivot[df_flow_pivot[targetCol].notnull()]\n",
    "# #     for course in Feature_Courses:\n",
    "# #         feature_col = ('amax', course)\n",
    "# #         df_flow_pivot = df_flow_pivot[df_flow_pivot[feature_col].notnull()]\n",
    "\n",
    "\n",
    "    df_flow_pivot = df_flow_pivot.sort_values(by=['NEW_COD_STUDENT','COURSE_ID', 'YEAR', 'SEMESTER'],ascending=[False, False, True,True])\n",
    "\n",
    "#     df_flow_pivot = df_flow_pivot.drop_duplicates(subset=['NEW_COD_STUDENT'], keep='last')\n",
    "    \n",
    "    df_flow_pivot.loc[(df_flow_pivot[targetCol] == 0), ('PrevLatestGrade', Target_Course)] = df_flow_pivot[(df_flow_pivot[targetCol] == 0)][('PrevLatestGrade', Target_Course)].mean()\n",
    "    \n",
    "#     df_flow_pivot[\"IS_REPEATER\"] = (df_flow_pivot[targetCol] > 0).astype(int)\n",
    "    df_flow_pivot[\"TargetGrade\"] = df_flow_pivot[('amax', Target_Course)]\n",
    "    df_flow_pivot[\"TargetCourse\"] = Target_Course\n",
    "    for column in df_flow_pivot:\n",
    "#         if column in Target_Courses_amax or Target_Courses_prev or Target_Courses_count:\n",
    "        if is_numeric_dtype(df_flow_pivot[column]):\n",
    "            df_flow_pivot[column].fillna((df_flow_pivot[column].mean()), inplace=True)\n",
    "        if column in Target_Courses_amax:\n",
    "#             print('col to delete: ', column)\n",
    "            df_flow_pivot = df_flow_pivot.drop(column, axis=1)\n",
    "\n",
    "    df_flow_pivot = df_flow_pivot[df_flow_pivot['COURSE_ID'] == Target_Course]\n",
    "    df_flow_pivot = df_flow_pivot.drop('COURSE_ID', axis=1)\n",
    "    print('Path: Exp: targetCoruse', MainPath + Experiment + \"\\\\\" + Target_Course + \"_flow_ready_unified.csv\")\n",
    "\n",
    "    df_flow_pivot2 = df_flow_pivot.to_csv (MainPath + Experiment + \"\\\\\" +  Target_Course + \"_flow_ready_unified.csv\", index = None, header=True)\n",
    "\n",
    "    return df_flow_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difficulty_features_extraction(cleaned_data, Experiment):\n",
    "#     df_flow = cleaned_data\n",
    "    cleaned_data.GRADE = cleaned_data.GRADE.replace({',': '.'}, regex=True)\n",
    "    cleaned_data.GRADE = pd.to_numeric(cleaned_data.GRADE)\n",
    "\n",
    "    df_flow_grouped = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"])['GRADE'].mean().reset_index()\n",
    "#     df_flow_grouped = cleaned_data.groupby([\"COURSE_ID\"])['GRADE'].mean().reset_index()\n",
    "\n",
    "#     df_flow_grouped['alpha_Num'] = cleaned_data.groupby([\"COURSE_ID\"])['GPA'].apply(Sum_GPA_Squared).reset_index()['GPA']\n",
    "    df_flow_grouped['alpha_Num'] = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"])['GPA'].apply(Sum_GPA_Squared).reset_index()['GPA']\n",
    "\n",
    "    df_flow_grouped['alpha_Denom'] = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"]).apply(Sum_GPAxMARK).reset_index()[0]\n",
    "#     df_flow_grouped['alpha_Denom'] = cleaned_data.groupby([\"COURSE_ID\"]).apply(Sum_GPAxMARK).reset_index()[0]\n",
    "\n",
    "    df_flow_grouped['alpha'] = df_flow_grouped['alpha_Num'] / df_flow_grouped['alpha_Denom']\n",
    "\n",
    "    df_flow_grouped['beta_Num'] = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"]).apply(Sum_GPAsubMARK).reset_index()[0]\n",
    "#     df_flow_grouped['beta_Num'] = cleaned_data.groupby([\"COURSE_ID\"]).apply(Sum_GPAsubMARK).reset_index()[0]\n",
    "#     df_flow_grouped['beta_Denom'] = cleaned_data.groupby([\"COURSE_ID\"])['GRADE'].count().reset_index()['GRADE']\n",
    "    df_flow_grouped['beta_Denom'] = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"])['GRADE'].count().reset_index()['GRADE']\n",
    "    df_flow_grouped['beta'] = df_flow_grouped['beta_Num'] / df_flow_grouped['beta_Denom']\n",
    "\n",
    "#     df_flow_grouped['Skewness'] = cleaned_data.groupby([\"COURSE_ID\"]).apply(SkewnessOfDifferences).reset_index()[0]\n",
    "    df_flow_grouped['Skewness'] = cleaned_data.groupby([\"COURSE_ID\", \"PROFESSOR_ID\"]).apply(SkewnessOfDifferences).reset_index()[0]\n",
    "    \n",
    "    df_flow_grouped2 = df_flow_grouped.to_csv (MainPath + Experiment  + \"\\\\Courses_difficulties.csv\", index = None, header=True)\n",
    "\n",
    "    return df_flow_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courses_load_features_extraction(allData, courses_difficulties, courses_credits, Experiment):\n",
    "    df_all_student_courses = allData\n",
    "    df_courses_difficulties = courses_difficulties\n",
    "    df_courses_credits = courses_credits\n",
    "\n",
    "\n",
    "    #merge to get other difficulties factor\n",
    "#     df_all_student_courses =  pd.merge(df_all_student_courses, df_courses_difficulties, on=[\"COURSE_ID\"])\n",
    "    df_all_student_courses =  pd.merge(df_all_student_courses, df_courses_difficulties, on=[\"COURSE_ID\", \"PROFESSOR_ID\"])\n",
    "    #merge to get Credits\n",
    "    df_all_student_courses =  pd.merge(df_all_student_courses, df_courses_credits, on=[\"COURSE_ID\"])\n",
    "\n",
    "#     grouped.filter(lambda x: x['B'].mean() > 3.)\n",
    "#     df_all_student_courses_agg = df_all_student_courses.groupby(['NEW_COD_STUDENT', 'YEAR', 'SEMESTER']).agg({'ID': 'count', 'alpha': 'max', 'beta': 'max', \"Course_Theoritical_Credits\":\"sum\", \"Course_Practical_Credits\":\"sum\", \"Skewness\" : \"mean\"}).reset_index()\n",
    "  \n",
    "    df_all_student_courses_agg = df_all_student_courses.loc[df_all_student_courses['COURSE_ID'] != 'FIEC01735'].groupby(['NEW_COD_STUDENT', 'YEAR', 'SEMESTER']).agg({'ID': 'count', 'alpha': 'max', 'beta': 'max', \"Course_Theoritical_Credits\":\"sum\", \"Course_Practical_Credits\":\"sum\", \"Skewness\" : \"mean\"}).reset_index()\n",
    "\n",
    "    df_all_student_courses_agg['Skewness_Target'] = df_courses_difficulties.loc[df_courses_difficulties['COURSE_ID'] == 'FIEC01735'].groupby(['COURSE_ID']).agg({'Skewness' : 'mean'}).reset_index().iloc[0]['Skewness'] \n",
    "    df_all_student_courses_agg['alpha_Target'] = df_courses_difficulties.loc[df_courses_difficulties['COURSE_ID'] == 'FIEC01735'].groupby(['COURSE_ID']).agg({'alpha' : 'max'}).reset_index().iloc[0]['alpha']\n",
    "    df_all_student_courses_agg['beta_Target'] = df_courses_difficulties.loc[df_courses_difficulties['COURSE_ID'] == 'FIEC01735'].groupby(['COURSE_ID']).agg({'beta' : 'max'}).reset_index().iloc[0]['beta']\n",
    "#     print(df_all_student_courses_agg)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    df_all_student_courses_agg.rename(columns={'ID': 'C_LOAD'}, inplace=True)\n",
    "\n",
    "    df_all_student_courses_agg2 = df_all_student_courses_agg.to_csv (MainPath + Experiment + \"\\\\C_LOAD.csv\", index = None, header=True)\n",
    "\n",
    "    \n",
    "    return df_all_student_courses_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalFeatures(marks_features, df_course_load, Experiment):  \n",
    "#     df_course_load = pd.read_csv (Path + \"C_LOAD.csv\")\n",
    "    final_dataset = pd.merge(marks_features, df_course_load, on=[\"NEW_COD_STUDENT\", \"YEAR\", \"SEMESTER\"])\n",
    "    \n",
    "    final_dataset = final_dataset.to_csv (MainPath + Experiment  + \"\\\\\" + Experiment + \"_flow_ready_unified_features.csv\", index = None, header=True)\n",
    "\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(Target_Courses, Courses_to_include, Target_Courses_amax, Target_Courses_prev, Target_Courses_count, Experiment):\n",
    "    historia_academia_path = OrPath + \"historia_academica_anonym.csv\"\n",
    "    teaching_materials_path = OrPath + \"materias_anonym_clean.csv\"\n",
    "    graduates_all_dep = OrPath + \"exAlumnosConHistoriaAcademica_anonym.csv\"\n",
    "    df_courses_credits = pd.read_csv (OrPath + \"COURSE_CREDITS.csv\") \n",
    "    \n",
    "    df_dataset = join_historic_data(historia_academia_path, teaching_materials_path, graduates_all_dep, Experiment)\n",
    "    cleaned_data = clean_dataset(df_dataset, Courses_to_include, Experiment)\n",
    "    \n",
    "    finalTargetCourses_Featrues = pd.DataFrame()\n",
    "    for course in Target_Courses:\n",
    "        marks_features = marks_features_extraction (cleaned_data, course, Target_Courses_amax, Experiment)\n",
    "        finalTargetCourses_Featrues = pd.concat([finalTargetCourses_Featrues, marks_features], axis=0)\n",
    "    \n",
    "    finalTargetCourses2 = finalTargetCourses_Featrues.to_csv (MainPath + Experiment  + \"\\\\finalTargetCourses.csv\", index = None, header=True)\n",
    "\n",
    "\n",
    "    \n",
    "    difficulty_features = difficulty_features_extraction (df_dataset, Experiment)\n",
    "    course_load_features = courses_load_features_extraction(df_dataset, difficulty_features, df_courses_credits, Experiment)\n",
    "    final_dataset = finalFeatures(finalTargetCourses_Featrues, course_load_features, Experiment)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line:  FIEC02097 FIEC03053 FIEC01545:FIEC03319 FIEC00299 FIEC01735 ICF00463 ICF00489 FIEC03046 FIEC05553 FIEC04622 FIEC04341\n",
      "\n",
      "final Target_Courses:  ['FIEC02097', 'FIEC03053', 'FIEC01545']\n",
      "final Courses_to_include:  ['FIEC02097', 'FIEC03053', 'FIEC01545', 'FIEC03319', 'FIEC00299', 'FIEC01735', 'ICF00463', 'ICF00489', 'FIEC03046', 'FIEC05553', 'FIEC04622', 'FIEC04341']\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment1\\FIEC02097_flow_ready_unified.csv\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment1\\FIEC03053_flow_ready_unified.csv\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment1\\FIEC01545_flow_ready_unified.csv\n",
      "Finish:  2\n",
      "line:  ICM00604 ICF00489 ICM00646 FIEC03012:ICM00216 ICF00463 FIEC04341 ICM00901\n",
      "final Target_Courses:  ['ICM00604', 'ICF00489', 'ICM00646', 'FIEC03012']\n",
      "final Courses_to_include:  ['ICM00604', 'ICF00489', 'ICM00646', 'FIEC03012', 'ICM00216', 'ICF00463', 'FIEC04341', 'ICM00901']\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment2\\ICM00604_flow_ready_unified.csv\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment2\\ICF00489_flow_ready_unified.csv\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment2\\ICM00646_flow_ready_unified.csv\n",
      "Path: Exp: targetCoruse C:\\Users\\mpouldou\\final-data\\Experiment2\\FIEC03012_flow_ready_unified.csv\n",
      "Finish:  3\n"
     ]
    }
   ],
   "source": [
    "def parseSemesterModels(filePath):\n",
    "    f = open(filePath)\n",
    "    experimentNo = 1\n",
    "    while True:\n",
    "        # read line\n",
    "        Courses_to_include = []\n",
    "        Target_Courses = []\n",
    "        Target_Courses_amax = []\n",
    "        Target_Courses_prev = []\n",
    "        Target_Courses_count = []\n",
    "        line = f.readline()\n",
    "        # check if line is not empty\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        print('line: ', line)\n",
    "        toPredict = line.split(\":\")[0]\n",
    "        prerequisite = line.split(\":\")[1]\n",
    "        Experiment = \"\\Experiment\" + str(experimentNo)\n",
    "        if not os.path.exists(MainPath + Experiment ):\n",
    "            os.mkdir(MainPath + Experiment )\n",
    "        for target in toPredict.split():\n",
    "                Target_Courses.append(target)\n",
    "                targetAmax = ('amax', target)\n",
    "                targetPrev = ('PrevLatestGrade', target)\n",
    "                targetCount = ('count', target)\n",
    "                Target_Courses_amax.append(targetAmax)\n",
    "                Target_Courses_prev.append(targetPrev)\n",
    "                Target_Courses_count.append(targetCount)\n",
    "                Courses_to_include.append(target)\n",
    "\n",
    "        for course in prerequisite.split():\n",
    "                Courses_to_include.append(course)\n",
    "    \n",
    "        print(\"final Target_Courses: \", Target_Courses)\n",
    "#         print(\"final Target_Courses_amax: \", Target_Courses_amax)\n",
    "#         print(\"final Target_Courses_prev: \", Target_Courses_prev)\n",
    "#         print(\"final Target_Courses_count: \", Target_Courses_count)\n",
    "        print(\"final Courses_to_include: \", Courses_to_include)\n",
    "        \n",
    "        experimentNo += 1\n",
    "        main(Target_Courses, Courses_to_include, Target_Courses_amax, Target_Courses_prev, Target_Courses_count, Experiment)  \n",
    "        print(\"Finish: \", experimentNo)\n",
    "    f.close()\n",
    "\n",
    "parseSemesterModels(semesterFilePath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
